{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_part2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAutNNniG1AD9S33LFWRD7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fenzhantw/DLforeveryone/blob/main/DeepLearning_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klLOioWcXjeG"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow.contrib.eager as tfe\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip uninstall tensorflow"
      ],
      "metadata": {
        "id": "kjvmNj-tXo3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==1.13.2"
      ],
      "metadata": {
        "id": "sAbR_-aCZyFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.enable_eager_execution()\n",
        "tf.set_random_seed(777)\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBAB9njaZ2Dw",
        "outputId": "e58a926e-ddd0-41a7-ce24-dc11425eb03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_data = [[0,0],\n",
        "          [0,1],\n",
        "          [1,0],\n",
        "          [1,1]]\n",
        "y_data = [[0],\n",
        "          [1],\n",
        "          [1],\n",
        "          [0]]"
      ],
      "metadata": {
        "id": "R-5MU1bSaW_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRl0abOkfzVM",
        "outputId": "2023dd57-bd10-41a9-c299-234341e4dd87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: id=424, shape=(4, 2), dtype=float32, numpy=\n",
              "array([[0., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.],\n",
              "       [1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset  = tf.data.Dataset.from_tensor_slices((X_data,y_data)).batch(len(X_data))"
      ],
      "metadata": {
        "id": "t31vWEVnayE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(features,labels):\n",
        "  features  = tf.cast(features,tf.float32)\n",
        "  labels = tf.cast(labels, tf.float32)\n",
        "  return features, labels"
      ],
      "metadata": {
        "id": "sVA48f1Ca3Na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = tf.Variable(tf.random_normal([2,1]),name='weight1')\n",
        "b1 = tf.Variable(tf.random_normal([1]),name='bias1')\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([2,1]),name='weight2')\n",
        "b2 = tf.Variable(tf.random_normal([1]),name='bias2')\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([2,1]),name='weight3')\n",
        "b3 = tf.Variable(tf.random_normal([1]),name='bias3')"
      ],
      "metadata": {
        "id": "UE4jRnqsbLbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def neural_net(features):\n",
        "  layer1 = tf.sigmoid(tf.matmul(features, W1) +b1)\n",
        "  layer2 = tf.sigmoid(tf.matmul(features, W2) +b2)\n",
        "  layer3 = tf.concat([layer1,layer2],-1)\n",
        "  layer3 = tf.reshape(layer3,shape =[-1,2])\n",
        "  hypothesis = tf.sigmoid(tf.matmul(layer3,W3) +b3)\n",
        "  return hypothesis\n",
        "\n",
        "def loss_fn(hypothesis,labels):\n",
        "  cost = -tf.reduce_mean(labels*tf.log(hypothesis)+(1-labels)*tf.log(1-hypothesis))\n",
        "  return cost\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "\n",
        "def accuracy_fn(hypothesis,labels):\n",
        "  predicted =  tf.cast(hypothesis > 0.5,dtype=tf.float32)\n",
        "  accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,labels),dtype=tf.float32))\n",
        "  return accuracy\n",
        "\n",
        "def grad(features,lables):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss_value = loss_fn(neural_net(features),features,labels)\n",
        "    return tape.gradient(loss_value,[W1,W2,W3,b1,b2,b3])\n",
        "\n",
        "EPOCHES = 50000\n",
        "\n",
        "for step in range(EPOCHES):\n",
        "  for features, labels in tfe.Iterator(dataset):\n",
        "      features, labels = preprocess_data(features,labels)\n",
        "      grads = grad(neural_net(features),labels)\n",
        "      optimizer.apply_gradients(grades_and_vars=zip(grads,[W1,W2,W3,b1,b2,b3]))\n",
        "      if step % 5000 == 0:\n",
        "        print(\"Iter: {},loss:{:.4f}\".format(step,loss_fn(nerual_net(features),labels)))\n",
        "X_data, y_data = preprocess_data(X_data,y_data)\n",
        "test_acc = accuracy_fn(neural_net(X_data),y_data)\n",
        "print(\"testset Accuracy:{:.4f\".format(test_acc))"
      ],
      "metadata": {
        "id": "N9J57lrUcZyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Relu"
      ],
      "metadata": {
        "id": "uwYpBSG9h5tE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from time import time\n",
        "import os"
      ],
      "metadata": {
        "id": "6Y5i4a3_h8su"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(train_data,test_data):\n",
        "  train_data = train_data.astype(np.float32)/255.0\n",
        "  test_data = test_data.astype(np.float32)/255.0\n",
        "  return train_data,test_data\n",
        "\n",
        "def load_mnist():\n",
        "  (train_data,train_labels),(test_data,test_labels) = mnist.load_data()\n",
        "  train_data = np.expand_dims(train_data,axis=-1)\n",
        "  test_data = np.expand_dims(test_data,axis=-1)\n",
        "  train_data,test_data = normalize(train_data,test_data)\n",
        "  train_labels = to_categorical(train_labels,10)\n",
        "  test_labels = to_categorical(test_labels,10)\n",
        "\n",
        "  return train_data,train_labels,test_data,test_labels\n",
        "\n",
        "def load(model, checkpoint_dir):\n",
        "    print(\" [*] Reading checkpoints...\")\n",
        "\n",
        "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
        "    if ckpt :\n",
        "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
        "        checkpoint = tf.train.Checkpoint(dnn=model)\n",
        "        checkpoint.restore(save_path=os.path.join(checkpoint_dir, ckpt_name))\n",
        "        counter = int(ckpt_name.split('-')[1])\n",
        "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
        "        return True, counter\n",
        "    else:\n",
        "        print(\" [*] Failed to find a checkpoint\")\n",
        "        return False, 0\n",
        "\n",
        "def check_folder(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "    return dir"
      ],
      "metadata": {
        "id": "7SSbnQMXfEB0"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class create_model_class(tf.keras.Model):\n",
        "    def __init__(self, label_dim):\n",
        "        super(create_model_class, self).__init__()\n",
        "        weight_init = tf.keras.initializers.RandomNormal()\n",
        "\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(flatten())\n",
        "\n",
        "        for i in range(2):\n",
        "            self.model.add(dense(256, weight_init))\n",
        "            self.model.add(relu())\n",
        "\n",
        "        self.model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "rj7DxcVEsKuu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create network\n",
        "#네트워크를 짤때 어떠한 함수를 이용할것인지 먼저 생각해야함\n",
        "\n",
        "#1.shape을 펼쳐주는 역할\n",
        "def flatten():\n",
        "  return tf.keras.layers.Flatten()\n",
        "\n",
        "#2.Dense layer를 사용할 것이기 때문에 kerase에 Dense를 만들어줌\n",
        "def dense(channel,weight_init):\n",
        "  return tf.keras.layers.Dense(units=channel,use_bias=True,kernel_initializer=weight_init)\n",
        "\n",
        "def relu():\n",
        "  return tf.keras.layers.Activation(tf.keras.activations.relu)\n",
        "\n",
        "#tf.keras.model을 상속해야 class 모델을 만들 수 있음\n",
        "class create_model(tf.keras.Model):\n",
        "  def __init__(self,label_dim):\n",
        "    super(create_model,self).__init__()\n",
        "\n",
        "    weight_init = tf.keras.initializers.RandomNormal()\n",
        "    self.model = tf.keras.Sequential()\n",
        "    self.model.add(flatten()) # [N,28,28,1] -> [N,784]\n",
        "\n",
        "    for i in range(2):\n",
        "      # [N,784] -> [N,256] -> [N, 256]\n",
        "      self.model.add(dense(256,weight_init))\n",
        "      self.model.add(relu())\n",
        "\n",
        "    self.model.add(dense(label_dim,weight_init)) # [N,256] -> [N,10]\n",
        "\n",
        "    def call(self,x,training=None,mask=None):\n",
        "      x=self.model(x)\n",
        "\n",
        "      return x\n",
        "\n",
        "#model,image,lable을 받음\n",
        "def loss_fn(model,images,labels):\n",
        "  #model에 image를 넣고, logit을 구함\n",
        "  logits = model(images,training=True)\n",
        "  #model에서 구한 softmax(logit)로 예측한 값과 lables의 차이를 loss를 구함\n",
        "  loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(y_pred=logits, y_true=labels, \n",
        "                                                                   from_logits=True))\n",
        "  return loss\n",
        "\n",
        "def accuracy_fn(model,images,labels):\n",
        "  logits = model(images,training=False)\n",
        "  #argmax는 logit과 label에서 가장 숫자가 큰 값의 위치를 알려주는 함수임 logit과 lable은 다음과 같이 이루어져 있음 -1은 lable_dim을 의미함. [batch size,label_dim]\n",
        "  prediction = tf.equal(tf.argmax(logits,-1),tf.argmax(labels,-1))\n",
        "  #accuracy를 구하는것은 boolen보다 숫자값으로 바꿔야 계산이 되기 때문에 바꾸어서 저장\n",
        "  accuracy = tf.reduce_mean(tf.cast(prediction,tf.float32))\n",
        "  return accuracy\n",
        "\n",
        "def grad(model,images,labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    loss = loss_fn(model,images,labels)\n",
        "  return tape.gradient(loss,model.variables)"
      ],
      "metadata": {
        "id": "QkBRq0VFfYAE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#하이퍼 파라미터 설정\n",
        "\n",
        "train_x,train_y,test_x,test_y = load_mnist()"
      ],
      "metadata": {
        "id": "QGQyjSc-flnd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" dataset \"\"\"\n",
        "train_x, train_y, test_x, test_y = load_mnist()\n",
        "\n",
        "\"\"\" parameters \"\"\"\n",
        "learning_rate = 0.001\n",
        "batch_size = 128\n",
        "\n",
        "training_epochs = 1\n",
        "training_iterations = len(train_x) // batch_size\n",
        "\n",
        "label_dim = 10\n",
        "\n",
        "train_flag = True\n",
        "\n",
        "#데이터가 6만장을 네트워크에 넣기에는 메모리에 부담을 주기 때문에, 배치사이즈 만큼 줘야 함 아래는, 그 배치를 어떻게 네트워크에 던져주느냐에 관한 이야기\n",
        "#shuffle 데이터셋을 잘 썩기,buffer_size는 데이터셋보다 커야함\n",
        "#prefetch 미리 메모리에 해당 배치사이즈 만큼 올려두어서 빠르게 학습 시키는 방법\n",
        "#batch   몇개 만큼 네트워크에 던져주는지?\n",
        "\"\"\" Graph Input using Dataset API \"\"\"\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).\\\n",
        "    shuffle(buffer_size=100000).\\\n",
        "    prefetch(buffer_size=batch_size).\\\n",
        "    batch(batch_size, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y)).\\\n",
        "    shuffle(buffer_size=100000).\\\n",
        "    prefetch(buffer_size=len(test_x)).\\\n",
        "    batch(len(test_x))"
      ],
      "metadata": {
        "id": "FVgkI12nr-sA"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network = create_model_class(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\"\"\" Writer \"\"\"\n",
        "checkpoint_dir = 'checkpoints'\n",
        "logs_dir = 'logs'\n",
        "\n",
        "model_dir = 'nn_softmax'\n",
        "\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "check_folder(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
        "logs_dir = os.path.join(logs_dir, model_dir)"
      ],
      "metadata": {
        "id": "vDeOeCHWrnU8"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_flag :\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(dnn=network)\n",
        "\n",
        "    # create writer for tensorboard\n",
        "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
        "    start_time = time()\n",
        "\n",
        "    # restore check-point if it exits\n",
        "    could_load, checkpoint_counter = load(network, checkpoint_dir)    \n",
        "\n",
        "    if could_load:\n",
        "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
        "        counter = checkpoint_counter        \n",
        "        print(\" [*] Load SUCCESS\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        start_iteration = 0\n",
        "        counter = 0\n",
        "        print(\" [!] Load failed...\")\n",
        "    \n",
        "    # train phase\n",
        "    with summary_writer.as_default():  # for tensorboard\n",
        "        for epoch in range(start_epoch, training_epochs):\n",
        "            for idx, (train_input, train_label) in enumerate(train_dataset):            \n",
        "                grads = grad(network, train_input, train_label)\n",
        "                optimizer.apply_gradients(grads_and_vars=zip(grads, network.variables))\n",
        "\n",
        "                train_loss = loss_fn(network, train_input, train_label)\n",
        "                train_accuracy = accuracy_fn(network, train_input, train_label)\n",
        "                \n",
        "                for test_input, test_label in test_dataset:                \n",
        "                    test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
        "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
        "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
        "\n",
        "                print(\n",
        "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
        "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
        "                       test_accuracy))\n",
        "                counter += 1                \n",
        "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
        "        \n",
        "# test phase      \n",
        "else :\n",
        "    _, _ = load(network, checkpoint_dir)\n",
        "    for test_input, test_label in test_dataset:    \n",
        "        test_accuracy = accuracy_fn(network, test_input, test_label)\n",
        "\n",
        "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iy7-TLUyMKLV",
        "outputId": "bf201b63-10f6-4610-9740-de5e7c6e7a97"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Reading checkpoints...\n",
            " [*] Failed to find a checkpoint\n",
            " [!] Load failed...\n",
            "Epoch: [ 0] [    0/  468] time: 0.6837, train_loss: 2.15999317, train_accuracy: 0.3828, test_Accuracy: 0.2937\n",
            "Epoch: [ 0] [    1/  468] time: 1.0490, train_loss: 2.13213396, train_accuracy: 0.5156, test_Accuracy: 0.4757\n",
            "Epoch: [ 0] [    2/  468] time: 1.4091, train_loss: 2.02703667, train_accuracy: 0.5703, test_Accuracy: 0.5426\n",
            "Epoch: [ 0] [    3/  468] time: 1.6543, train_loss: 1.98404002, train_accuracy: 0.5859, test_Accuracy: 0.6182\n",
            "Epoch: [ 0] [    4/  468] time: 1.9149, train_loss: 1.90166497, train_accuracy: 0.6250, test_Accuracy: 0.6411\n",
            "Epoch: [ 0] [    5/  468] time: 2.1568, train_loss: 1.84366655, train_accuracy: 0.6406, test_Accuracy: 0.6650\n",
            "Epoch: [ 0] [    6/  468] time: 2.5194, train_loss: 1.71306193, train_accuracy: 0.6641, test_Accuracy: 0.7028\n",
            "Epoch: [ 0] [    7/  468] time: 2.7617, train_loss: 1.56476462, train_accuracy: 0.7578, test_Accuracy: 0.7177\n",
            "Epoch: [ 0] [    8/  468] time: 3.1305, train_loss: 1.44232106, train_accuracy: 0.7578, test_Accuracy: 0.7182\n",
            "Epoch: [ 0] [    9/  468] time: 3.4071, train_loss: 1.44300020, train_accuracy: 0.7266, test_Accuracy: 0.7234\n",
            "Epoch: [ 0] [   10/  468] time: 3.6547, train_loss: 1.37184370, train_accuracy: 0.6953, test_Accuracy: 0.7209\n",
            "Epoch: [ 0] [   11/  468] time: 3.9082, train_loss: 1.22103953, train_accuracy: 0.7500, test_Accuracy: 0.7377\n",
            "Epoch: [ 0] [   12/  468] time: 4.2684, train_loss: 1.18513298, train_accuracy: 0.6953, test_Accuracy: 0.7601\n",
            "Epoch: [ 0] [   13/  468] time: 4.5150, train_loss: 0.98347044, train_accuracy: 0.7891, test_Accuracy: 0.7874\n",
            "Epoch: [ 0] [   14/  468] time: 4.7502, train_loss: 0.90895998, train_accuracy: 0.8359, test_Accuracy: 0.8073\n",
            "Epoch: [ 0] [   15/  468] time: 4.9958, train_loss: 0.92027366, train_accuracy: 0.8203, test_Accuracy: 0.8206\n",
            "Epoch: [ 0] [   16/  468] time: 5.3506, train_loss: 0.74769282, train_accuracy: 0.8438, test_Accuracy: 0.8129\n",
            "Epoch: [ 0] [   17/  468] time: 5.5878, train_loss: 0.83924794, train_accuracy: 0.7734, test_Accuracy: 0.8020\n",
            "Epoch: [ 0] [   18/  468] time: 5.8253, train_loss: 0.70440322, train_accuracy: 0.7891, test_Accuracy: 0.8050\n",
            "Epoch: [ 0] [   19/  468] time: 6.0691, train_loss: 0.73181152, train_accuracy: 0.8359, test_Accuracy: 0.8228\n",
            "Epoch: [ 0] [   20/  468] time: 6.3153, train_loss: 0.67226893, train_accuracy: 0.8438, test_Accuracy: 0.8374\n",
            "Epoch: [ 0] [   21/  468] time: 6.5570, train_loss: 0.52304071, train_accuracy: 0.8516, test_Accuracy: 0.8335\n",
            "Epoch: [ 0] [   22/  468] time: 6.7946, train_loss: 0.54868627, train_accuracy: 0.8516, test_Accuracy: 0.8292\n",
            "Epoch: [ 0] [   23/  468] time: 7.0265, train_loss: 0.49913594, train_accuracy: 0.8359, test_Accuracy: 0.8230\n",
            "Epoch: [ 0] [   24/  468] time: 7.2677, train_loss: 0.51217401, train_accuracy: 0.7969, test_Accuracy: 0.8290\n",
            "Epoch: [ 0] [   25/  468] time: 7.5083, train_loss: 0.53721720, train_accuracy: 0.8594, test_Accuracy: 0.8393\n",
            "Epoch: [ 0] [   26/  468] time: 7.7434, train_loss: 0.48184749, train_accuracy: 0.8516, test_Accuracy: 0.8404\n",
            "Epoch: [ 0] [   27/  468] time: 7.9957, train_loss: 0.46759272, train_accuracy: 0.8828, test_Accuracy: 0.8356\n",
            "Epoch: [ 0] [   28/  468] time: 8.2366, train_loss: 0.58122170, train_accuracy: 0.8047, test_Accuracy: 0.8353\n",
            "Epoch: [ 0] [   29/  468] time: 8.4969, train_loss: 0.49545598, train_accuracy: 0.8359, test_Accuracy: 0.8448\n",
            "Epoch: [ 0] [   30/  468] time: 8.8606, train_loss: 0.66095698, train_accuracy: 0.8203, test_Accuracy: 0.8564\n",
            "Epoch: [ 0] [   31/  468] time: 9.2204, train_loss: 0.40519693, train_accuracy: 0.8906, test_Accuracy: 0.8645\n",
            "Epoch: [ 0] [   32/  468] time: 9.4543, train_loss: 0.57068521, train_accuracy: 0.8203, test_Accuracy: 0.8674\n",
            "Epoch: [ 0] [   33/  468] time: 9.8190, train_loss: 0.60014760, train_accuracy: 0.8047, test_Accuracy: 0.8612\n",
            "Epoch: [ 0] [   34/  468] time: 10.0649, train_loss: 0.40316337, train_accuracy: 0.8828, test_Accuracy: 0.8500\n",
            "Epoch: [ 0] [   35/  468] time: 10.3138, train_loss: 0.32416284, train_accuracy: 0.8828, test_Accuracy: 0.8434\n",
            "Epoch: [ 0] [   36/  468] time: 10.5576, train_loss: 0.36846855, train_accuracy: 0.8828, test_Accuracy: 0.8485\n",
            "Epoch: [ 0] [   37/  468] time: 10.8024, train_loss: 0.46627098, train_accuracy: 0.8906, test_Accuracy: 0.8651\n",
            "Epoch: [ 0] [   38/  468] time: 11.0647, train_loss: 0.29569447, train_accuracy: 0.9219, test_Accuracy: 0.8713\n",
            "Epoch: [ 0] [   39/  468] time: 11.4228, train_loss: 0.43947029, train_accuracy: 0.8516, test_Accuracy: 0.8647\n",
            "Epoch: [ 0] [   40/  468] time: 11.6740, train_loss: 0.43654096, train_accuracy: 0.8750, test_Accuracy: 0.8553\n",
            "Epoch: [ 0] [   41/  468] time: 11.9129, train_loss: 0.52573669, train_accuracy: 0.8750, test_Accuracy: 0.8555\n",
            "Epoch: [ 0] [   42/  468] time: 12.2696, train_loss: 0.36396062, train_accuracy: 0.8828, test_Accuracy: 0.8650\n",
            "Epoch: [ 0] [   43/  468] time: 12.6323, train_loss: 0.49205959, train_accuracy: 0.8750, test_Accuracy: 0.8782\n",
            "Epoch: [ 0] [   44/  468] time: 12.8855, train_loss: 0.35185036, train_accuracy: 0.8438, test_Accuracy: 0.8844\n",
            "Epoch: [ 0] [   45/  468] time: 13.1396, train_loss: 0.29145512, train_accuracy: 0.9219, test_Accuracy: 0.8882\n",
            "Epoch: [ 0] [   46/  468] time: 13.3850, train_loss: 0.46324670, train_accuracy: 0.8672, test_Accuracy: 0.8892\n",
            "Epoch: [ 0] [   47/  468] time: 13.7606, train_loss: 0.44175273, train_accuracy: 0.8906, test_Accuracy: 0.8890\n",
            "Epoch: [ 0] [   48/  468] time: 14.0060, train_loss: 0.28476843, train_accuracy: 0.9219, test_Accuracy: 0.8859\n",
            "Epoch: [ 0] [   49/  468] time: 14.2639, train_loss: 0.40022600, train_accuracy: 0.8906, test_Accuracy: 0.8847\n",
            "Epoch: [ 0] [   50/  468] time: 14.5153, train_loss: 0.52331758, train_accuracy: 0.8594, test_Accuracy: 0.8910\n",
            "Epoch: [ 0] [   51/  468] time: 14.7588, train_loss: 0.33270341, train_accuracy: 0.9141, test_Accuracy: 0.8959\n",
            "Epoch: [ 0] [   52/  468] time: 15.0059, train_loss: 0.35416460, train_accuracy: 0.8906, test_Accuracy: 0.8931\n",
            "Epoch: [ 0] [   53/  468] time: 15.2637, train_loss: 0.37007481, train_accuracy: 0.9141, test_Accuracy: 0.8887\n",
            "Epoch: [ 0] [   54/  468] time: 15.5128, train_loss: 0.41814086, train_accuracy: 0.8750, test_Accuracy: 0.8904\n",
            "Epoch: [ 0] [   55/  468] time: 15.7694, train_loss: 0.40065515, train_accuracy: 0.8828, test_Accuracy: 0.8941\n",
            "Epoch: [ 0] [   56/  468] time: 16.0184, train_loss: 0.27848202, train_accuracy: 0.9219, test_Accuracy: 0.8957\n",
            "Epoch: [ 0] [   57/  468] time: 16.3768, train_loss: 0.25246686, train_accuracy: 0.9375, test_Accuracy: 0.8922\n",
            "Epoch: [ 0] [   58/  468] time: 16.6352, train_loss: 0.25628960, train_accuracy: 0.9141, test_Accuracy: 0.8902\n",
            "Epoch: [ 0] [   59/  468] time: 16.8829, train_loss: 0.36284894, train_accuracy: 0.8906, test_Accuracy: 0.8929\n",
            "Epoch: [ 0] [   60/  468] time: 17.1450, train_loss: 0.40828022, train_accuracy: 0.8906, test_Accuracy: 0.8974\n",
            "Epoch: [ 0] [   61/  468] time: 17.4015, train_loss: 0.29917568, train_accuracy: 0.9062, test_Accuracy: 0.8994\n",
            "Epoch: [ 0] [   62/  468] time: 17.6586, train_loss: 0.37623310, train_accuracy: 0.8672, test_Accuracy: 0.8982\n",
            "Epoch: [ 0] [   63/  468] time: 17.9251, train_loss: 0.49300811, train_accuracy: 0.8672, test_Accuracy: 0.8973\n",
            "Epoch: [ 0] [   64/  468] time: 18.2826, train_loss: 0.37220368, train_accuracy: 0.8984, test_Accuracy: 0.8956\n",
            "Epoch: [ 0] [   65/  468] time: 18.5325, train_loss: 0.41186655, train_accuracy: 0.8828, test_Accuracy: 0.8929\n",
            "Epoch: [ 0] [   66/  468] time: 18.7859, train_loss: 0.28064227, train_accuracy: 0.8984, test_Accuracy: 0.8925\n",
            "Epoch: [ 0] [   67/  468] time: 19.0329, train_loss: 0.21991184, train_accuracy: 0.9453, test_Accuracy: 0.8963\n",
            "Epoch: [ 0] [   68/  468] time: 19.2887, train_loss: 0.31776488, train_accuracy: 0.8984, test_Accuracy: 0.9043\n",
            "Epoch: [ 0] [   69/  468] time: 19.5483, train_loss: 0.28499383, train_accuracy: 0.9297, test_Accuracy: 0.9068\n",
            "Epoch: [ 0] [   70/  468] time: 19.9108, train_loss: 0.35042891, train_accuracy: 0.8984, test_Accuracy: 0.9037\n",
            "Epoch: [ 0] [   71/  468] time: 20.1591, train_loss: 0.18553665, train_accuracy: 0.9609, test_Accuracy: 0.8983\n",
            "Epoch: [ 0] [   72/  468] time: 20.4166, train_loss: 0.23097357, train_accuracy: 0.9219, test_Accuracy: 0.8939\n",
            "Epoch: [ 0] [   73/  468] time: 20.6774, train_loss: 0.31100753, train_accuracy: 0.9062, test_Accuracy: 0.8957\n",
            "Epoch: [ 0] [   74/  468] time: 20.9241, train_loss: 0.40713844, train_accuracy: 0.8750, test_Accuracy: 0.8996\n",
            "Epoch: [ 0] [   75/  468] time: 21.1728, train_loss: 0.31046039, train_accuracy: 0.9141, test_Accuracy: 0.9048\n",
            "Epoch: [ 0] [   76/  468] time: 21.5366, train_loss: 0.44272304, train_accuracy: 0.8438, test_Accuracy: 0.9083\n",
            "Epoch: [ 0] [   77/  468] time: 21.8956, train_loss: 0.37244546, train_accuracy: 0.8594, test_Accuracy: 0.9113\n",
            "Epoch: [ 0] [   78/  468] time: 22.2565, train_loss: 0.25454271, train_accuracy: 0.9375, test_Accuracy: 0.9092\n",
            "Epoch: [ 0] [   79/  468] time: 22.5076, train_loss: 0.32216048, train_accuracy: 0.9219, test_Accuracy: 0.9064\n",
            "Epoch: [ 0] [   80/  468] time: 22.7562, train_loss: 0.44546470, train_accuracy: 0.8438, test_Accuracy: 0.9069\n",
            "Epoch: [ 0] [   81/  468] time: 22.9953, train_loss: 0.31199864, train_accuracy: 0.8906, test_Accuracy: 0.9062\n",
            "Epoch: [ 0] [   82/  468] time: 23.2384, train_loss: 0.34731358, train_accuracy: 0.8906, test_Accuracy: 0.9091\n",
            "Epoch: [ 0] [   83/  468] time: 23.6041, train_loss: 0.31316209, train_accuracy: 0.8750, test_Accuracy: 0.9096\n",
            "Epoch: [ 0] [   84/  468] time: 23.8524, train_loss: 0.27031171, train_accuracy: 0.8984, test_Accuracy: 0.9090\n",
            "Epoch: [ 0] [   85/  468] time: 24.1074, train_loss: 0.36547944, train_accuracy: 0.8828, test_Accuracy: 0.9088\n",
            "Epoch: [ 0] [   86/  468] time: 24.3629, train_loss: 0.21473002, train_accuracy: 0.9297, test_Accuracy: 0.9092\n",
            "Epoch: [ 0] [   87/  468] time: 24.6031, train_loss: 0.28059232, train_accuracy: 0.8984, test_Accuracy: 0.9073\n",
            "Epoch: [ 0] [   88/  468] time: 24.8503, train_loss: 0.30688965, train_accuracy: 0.9062, test_Accuracy: 0.9066\n",
            "Epoch: [ 0] [   89/  468] time: 25.2063, train_loss: 0.39801189, train_accuracy: 0.8828, test_Accuracy: 0.9083\n",
            "Epoch: [ 0] [   90/  468] time: 25.5731, train_loss: 0.31714666, train_accuracy: 0.8906, test_Accuracy: 0.9101\n",
            "Epoch: [ 0] [   91/  468] time: 25.8221, train_loss: 0.21365562, train_accuracy: 0.9531, test_Accuracy: 0.9126\n",
            "Epoch: [ 0] [   92/  468] time: 26.0647, train_loss: 0.23248518, train_accuracy: 0.9375, test_Accuracy: 0.9112\n",
            "Epoch: [ 0] [   93/  468] time: 26.3034, train_loss: 0.32336345, train_accuracy: 0.9141, test_Accuracy: 0.9118\n",
            "Epoch: [ 0] [   94/  468] time: 26.5509, train_loss: 0.25359550, train_accuracy: 0.9141, test_Accuracy: 0.9116\n",
            "Epoch: [ 0] [   95/  468] time: 26.8016, train_loss: 0.27169362, train_accuracy: 0.9297, test_Accuracy: 0.9128\n",
            "Epoch: [ 0] [   96/  468] time: 27.0443, train_loss: 0.28157392, train_accuracy: 0.9062, test_Accuracy: 0.9140\n",
            "Epoch: [ 0] [   97/  468] time: 27.2904, train_loss: 0.28288615, train_accuracy: 0.9219, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [   98/  468] time: 27.6468, train_loss: 0.25173610, train_accuracy: 0.9062, test_Accuracy: 0.9148\n",
            "Epoch: [ 0] [   99/  468] time: 27.8914, train_loss: 0.20208195, train_accuracy: 0.9297, test_Accuracy: 0.9143\n",
            "Epoch: [ 0] [  100/  468] time: 28.1299, train_loss: 0.32723647, train_accuracy: 0.8828, test_Accuracy: 0.9126\n",
            "Epoch: [ 0] [  101/  468] time: 28.3704, train_loss: 0.25065732, train_accuracy: 0.9297, test_Accuracy: 0.9149\n",
            "Epoch: [ 0] [  102/  468] time: 28.7415, train_loss: 0.25856203, train_accuracy: 0.9219, test_Accuracy: 0.9185\n",
            "Epoch: [ 0] [  103/  468] time: 28.9815, train_loss: 0.25842994, train_accuracy: 0.9375, test_Accuracy: 0.9192\n",
            "Epoch: [ 0] [  104/  468] time: 29.2178, train_loss: 0.19467385, train_accuracy: 0.9219, test_Accuracy: 0.9185\n",
            "Epoch: [ 0] [  105/  468] time: 29.4659, train_loss: 0.35068762, train_accuracy: 0.9141, test_Accuracy: 0.9175\n",
            "Epoch: [ 0] [  106/  468] time: 29.8307, train_loss: 0.28447032, train_accuracy: 0.8906, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [  107/  468] time: 30.0776, train_loss: 0.26236555, train_accuracy: 0.9453, test_Accuracy: 0.9152\n",
            "Epoch: [ 0] [  108/  468] time: 30.3279, train_loss: 0.32594854, train_accuracy: 0.9062, test_Accuracy: 0.9161\n",
            "Epoch: [ 0] [  109/  468] time: 30.5733, train_loss: 0.32991591, train_accuracy: 0.9141, test_Accuracy: 0.9150\n",
            "Epoch: [ 0] [  110/  468] time: 30.8200, train_loss: 0.18006760, train_accuracy: 0.9531, test_Accuracy: 0.9143\n",
            "Epoch: [ 0] [  111/  468] time: 31.0689, train_loss: 0.25649512, train_accuracy: 0.9297, test_Accuracy: 0.9143\n",
            "Epoch: [ 0] [  112/  468] time: 31.3137, train_loss: 0.27056777, train_accuracy: 0.9141, test_Accuracy: 0.9185\n",
            "Epoch: [ 0] [  113/  468] time: 31.5697, train_loss: 0.23217486, train_accuracy: 0.9375, test_Accuracy: 0.9206\n",
            "Epoch: [ 0] [  114/  468] time: 31.8185, train_loss: 0.27404156, train_accuracy: 0.8984, test_Accuracy: 0.9243\n",
            "Epoch: [ 0] [  115/  468] time: 32.0581, train_loss: 0.40354308, train_accuracy: 0.8906, test_Accuracy: 0.9265\n",
            "Epoch: [ 0] [  116/  468] time: 32.2939, train_loss: 0.24892876, train_accuracy: 0.9297, test_Accuracy: 0.9227\n",
            "Epoch: [ 0] [  117/  468] time: 32.5439, train_loss: 0.32771778, train_accuracy: 0.9141, test_Accuracy: 0.9207\n",
            "Epoch: [ 0] [  118/  468] time: 32.7779, train_loss: 0.29779872, train_accuracy: 0.9141, test_Accuracy: 0.9221\n",
            "Epoch: [ 0] [  119/  468] time: 33.0210, train_loss: 0.30065864, train_accuracy: 0.9141, test_Accuracy: 0.9248\n",
            "Epoch: [ 0] [  120/  468] time: 33.2815, train_loss: 0.25851798, train_accuracy: 0.9062, test_Accuracy: 0.9259\n",
            "Epoch: [ 0] [  121/  468] time: 33.5208, train_loss: 0.23484012, train_accuracy: 0.9453, test_Accuracy: 0.9258\n",
            "Epoch: [ 0] [  122/  468] time: 33.7760, train_loss: 0.15287480, train_accuracy: 0.9609, test_Accuracy: 0.9278\n",
            "Epoch: [ 0] [  123/  468] time: 34.1322, train_loss: 0.31248605, train_accuracy: 0.9141, test_Accuracy: 0.9232\n",
            "Epoch: [ 0] [  124/  468] time: 34.4958, train_loss: 0.33101517, train_accuracy: 0.8828, test_Accuracy: 0.9192\n",
            "Epoch: [ 0] [  125/  468] time: 34.8684, train_loss: 0.25017324, train_accuracy: 0.9219, test_Accuracy: 0.9178\n",
            "Epoch: [ 0] [  126/  468] time: 35.1393, train_loss: 0.19738150, train_accuracy: 0.9297, test_Accuracy: 0.9172\n",
            "Epoch: [ 0] [  127/  468] time: 35.3955, train_loss: 0.25038117, train_accuracy: 0.9375, test_Accuracy: 0.9158\n",
            "Epoch: [ 0] [  128/  468] time: 35.6440, train_loss: 0.22509629, train_accuracy: 0.9453, test_Accuracy: 0.9158\n",
            "Epoch: [ 0] [  129/  468] time: 36.0068, train_loss: 0.30499363, train_accuracy: 0.8984, test_Accuracy: 0.9165\n",
            "Epoch: [ 0] [  130/  468] time: 36.2498, train_loss: 0.26032513, train_accuracy: 0.9453, test_Accuracy: 0.9148\n",
            "Epoch: [ 0] [  131/  468] time: 36.4869, train_loss: 0.20441827, train_accuracy: 0.9531, test_Accuracy: 0.9122\n",
            "Epoch: [ 0] [  132/  468] time: 36.7341, train_loss: 0.31962654, train_accuracy: 0.9219, test_Accuracy: 0.9150\n",
            "Epoch: [ 0] [  133/  468] time: 36.9871, train_loss: 0.29785782, train_accuracy: 0.9141, test_Accuracy: 0.9196\n",
            "Epoch: [ 0] [  134/  468] time: 37.2473, train_loss: 0.41902420, train_accuracy: 0.8594, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  135/  468] time: 37.4876, train_loss: 0.27457964, train_accuracy: 0.9453, test_Accuracy: 0.9242\n",
            "Epoch: [ 0] [  136/  468] time: 37.7464, train_loss: 0.17375585, train_accuracy: 0.9375, test_Accuracy: 0.9218\n",
            "Epoch: [ 0] [  137/  468] time: 37.9970, train_loss: 0.35261890, train_accuracy: 0.8750, test_Accuracy: 0.9193\n",
            "Epoch: [ 0] [  138/  468] time: 38.2454, train_loss: 0.14913976, train_accuracy: 0.9609, test_Accuracy: 0.9181\n",
            "Epoch: [ 0] [  139/  468] time: 38.4821, train_loss: 0.23519330, train_accuracy: 0.9297, test_Accuracy: 0.9150\n",
            "Epoch: [ 0] [  140/  468] time: 38.7379, train_loss: 0.25532863, train_accuracy: 0.9297, test_Accuracy: 0.9143\n",
            "Epoch: [ 0] [  141/  468] time: 39.0957, train_loss: 0.27106896, train_accuracy: 0.9062, test_Accuracy: 0.9183\n",
            "Epoch: [ 0] [  142/  468] time: 39.3357, train_loss: 0.36073610, train_accuracy: 0.9141, test_Accuracy: 0.9184\n",
            "Epoch: [ 0] [  143/  468] time: 39.5866, train_loss: 0.25892559, train_accuracy: 0.9141, test_Accuracy: 0.9198\n",
            "Epoch: [ 0] [  144/  468] time: 39.8410, train_loss: 0.25574616, train_accuracy: 0.9453, test_Accuracy: 0.9200\n",
            "Epoch: [ 0] [  145/  468] time: 40.0842, train_loss: 0.20671198, train_accuracy: 0.9219, test_Accuracy: 0.9154\n",
            "Epoch: [ 0] [  146/  468] time: 40.3335, train_loss: 0.18972094, train_accuracy: 0.9531, test_Accuracy: 0.9142\n",
            "Epoch: [ 0] [  147/  468] time: 40.5796, train_loss: 0.24676925, train_accuracy: 0.9219, test_Accuracy: 0.9149\n",
            "Epoch: [ 0] [  148/  468] time: 40.8429, train_loss: 0.31620306, train_accuracy: 0.8906, test_Accuracy: 0.9202\n",
            "Epoch: [ 0] [  149/  468] time: 41.0763, train_loss: 0.29405195, train_accuracy: 0.8984, test_Accuracy: 0.9276\n",
            "Epoch: [ 0] [  150/  468] time: 41.3219, train_loss: 0.18476190, train_accuracy: 0.9609, test_Accuracy: 0.9294\n",
            "Epoch: [ 0] [  151/  468] time: 41.5638, train_loss: 0.15894179, train_accuracy: 0.9531, test_Accuracy: 0.9250\n",
            "Epoch: [ 0] [  152/  468] time: 41.8174, train_loss: 0.22961773, train_accuracy: 0.9297, test_Accuracy: 0.9207\n",
            "Epoch: [ 0] [  153/  468] time: 42.0576, train_loss: 0.22064933, train_accuracy: 0.9375, test_Accuracy: 0.9190\n",
            "Epoch: [ 0] [  154/  468] time: 42.3015, train_loss: 0.20903370, train_accuracy: 0.9453, test_Accuracy: 0.9241\n",
            "Epoch: [ 0] [  155/  468] time: 42.5465, train_loss: 0.19771662, train_accuracy: 0.9453, test_Accuracy: 0.9283\n",
            "Epoch: [ 0] [  156/  468] time: 42.7819, train_loss: 0.23647735, train_accuracy: 0.9219, test_Accuracy: 0.9294\n",
            "Epoch: [ 0] [  157/  468] time: 43.0268, train_loss: 0.21275789, train_accuracy: 0.9375, test_Accuracy: 0.9282\n",
            "Epoch: [ 0] [  158/  468] time: 43.3813, train_loss: 0.18057108, train_accuracy: 0.9453, test_Accuracy: 0.9253\n",
            "Epoch: [ 0] [  159/  468] time: 43.6467, train_loss: 0.16226608, train_accuracy: 0.9531, test_Accuracy: 0.9218\n",
            "Epoch: [ 0] [  160/  468] time: 43.8847, train_loss: 0.23272273, train_accuracy: 0.9297, test_Accuracy: 0.9210\n",
            "Epoch: [ 0] [  161/  468] time: 44.1240, train_loss: 0.28510362, train_accuracy: 0.9141, test_Accuracy: 0.9252\n",
            "Epoch: [ 0] [  162/  468] time: 44.3597, train_loss: 0.18673328, train_accuracy: 0.9453, test_Accuracy: 0.9294\n",
            "Epoch: [ 0] [  163/  468] time: 44.5951, train_loss: 0.31112057, train_accuracy: 0.9062, test_Accuracy: 0.9317\n",
            "Epoch: [ 0] [  164/  468] time: 44.8332, train_loss: 0.29363769, train_accuracy: 0.9141, test_Accuracy: 0.9299\n",
            "Epoch: [ 0] [  165/  468] time: 45.0771, train_loss: 0.24135248, train_accuracy: 0.9062, test_Accuracy: 0.9271\n",
            "Epoch: [ 0] [  166/  468] time: 45.3127, train_loss: 0.19175971, train_accuracy: 0.9453, test_Accuracy: 0.9251\n",
            "Epoch: [ 0] [  167/  468] time: 45.5443, train_loss: 0.16796426, train_accuracy: 0.9688, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  168/  468] time: 45.7765, train_loss: 0.24432839, train_accuracy: 0.9375, test_Accuracy: 0.9252\n",
            "Epoch: [ 0] [  169/  468] time: 46.0153, train_loss: 0.20550175, train_accuracy: 0.9297, test_Accuracy: 0.9276\n",
            "Epoch: [ 0] [  170/  468] time: 46.2569, train_loss: 0.21452762, train_accuracy: 0.9453, test_Accuracy: 0.9316\n",
            "Epoch: [ 0] [  171/  468] time: 46.6177, train_loss: 0.13755199, train_accuracy: 0.9609, test_Accuracy: 0.9351\n",
            "Epoch: [ 0] [  172/  468] time: 46.8527, train_loss: 0.15406427, train_accuracy: 0.9609, test_Accuracy: 0.9353\n",
            "Epoch: [ 0] [  173/  468] time: 47.1006, train_loss: 0.30492723, train_accuracy: 0.9141, test_Accuracy: 0.9306\n",
            "Epoch: [ 0] [  174/  468] time: 47.3353, train_loss: 0.28400922, train_accuracy: 0.9219, test_Accuracy: 0.9247\n",
            "Epoch: [ 0] [  175/  468] time: 47.5706, train_loss: 0.34623706, train_accuracy: 0.8828, test_Accuracy: 0.9231\n",
            "Epoch: [ 0] [  176/  468] time: 47.8062, train_loss: 0.19838558, train_accuracy: 0.9375, test_Accuracy: 0.9251\n",
            "Epoch: [ 0] [  177/  468] time: 48.0559, train_loss: 0.19166903, train_accuracy: 0.9453, test_Accuracy: 0.9284\n",
            "Epoch: [ 0] [  178/  468] time: 48.2983, train_loss: 0.14393038, train_accuracy: 0.9531, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  179/  468] time: 48.5321, train_loss: 0.25516519, train_accuracy: 0.9141, test_Accuracy: 0.9330\n",
            "Epoch: [ 0] [  180/  468] time: 48.7615, train_loss: 0.17234491, train_accuracy: 0.9688, test_Accuracy: 0.9339\n",
            "Epoch: [ 0] [  181/  468] time: 49.0090, train_loss: 0.29276550, train_accuracy: 0.9297, test_Accuracy: 0.9320\n",
            "Epoch: [ 0] [  182/  468] time: 49.3650, train_loss: 0.18353415, train_accuracy: 0.9531, test_Accuracy: 0.9310\n",
            "Epoch: [ 0] [  183/  468] time: 49.6186, train_loss: 0.23226616, train_accuracy: 0.9375, test_Accuracy: 0.9316\n",
            "Epoch: [ 0] [  184/  468] time: 49.8546, train_loss: 0.17784059, train_accuracy: 0.9453, test_Accuracy: 0.9324\n",
            "Epoch: [ 0] [  185/  468] time: 50.1047, train_loss: 0.30238810, train_accuracy: 0.9219, test_Accuracy: 0.9350\n",
            "Epoch: [ 0] [  186/  468] time: 50.4686, train_loss: 0.25347656, train_accuracy: 0.9453, test_Accuracy: 0.9361\n",
            "Epoch: [ 0] [  187/  468] time: 50.7120, train_loss: 0.16405362, train_accuracy: 0.9609, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  188/  468] time: 50.9427, train_loss: 0.25825900, train_accuracy: 0.9141, test_Accuracy: 0.9344\n",
            "Epoch: [ 0] [  189/  468] time: 51.1963, train_loss: 0.15557307, train_accuracy: 0.9375, test_Accuracy: 0.9311\n",
            "Epoch: [ 0] [  190/  468] time: 51.4437, train_loss: 0.19029787, train_accuracy: 0.9453, test_Accuracy: 0.9305\n",
            "Epoch: [ 0] [  191/  468] time: 51.6769, train_loss: 0.27370352, train_accuracy: 0.9375, test_Accuracy: 0.9291\n",
            "Epoch: [ 0] [  192/  468] time: 52.0435, train_loss: 0.24022871, train_accuracy: 0.9297, test_Accuracy: 0.9263\n",
            "Epoch: [ 0] [  193/  468] time: 52.2836, train_loss: 0.30897456, train_accuracy: 0.9062, test_Accuracy: 0.9287\n",
            "Epoch: [ 0] [  194/  468] time: 52.5295, train_loss: 0.21379374, train_accuracy: 0.9219, test_Accuracy: 0.9319\n",
            "Epoch: [ 0] [  195/  468] time: 52.7611, train_loss: 0.34889039, train_accuracy: 0.8906, test_Accuracy: 0.9340\n",
            "Epoch: [ 0] [  196/  468] time: 53.0051, train_loss: 0.33027339, train_accuracy: 0.9219, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  197/  468] time: 53.2604, train_loss: 0.16329214, train_accuracy: 0.9609, test_Accuracy: 0.9335\n",
            "Epoch: [ 0] [  198/  468] time: 53.4926, train_loss: 0.19144294, train_accuracy: 0.9531, test_Accuracy: 0.9325\n",
            "Epoch: [ 0] [  199/  468] time: 53.7329, train_loss: 0.25017512, train_accuracy: 0.9297, test_Accuracy: 0.9294\n",
            "Epoch: [ 0] [  200/  468] time: 53.9986, train_loss: 0.25651333, train_accuracy: 0.9453, test_Accuracy: 0.9305\n",
            "Epoch: [ 0] [  201/  468] time: 54.2496, train_loss: 0.19075395, train_accuracy: 0.9453, test_Accuracy: 0.9332\n",
            "Epoch: [ 0] [  202/  468] time: 54.4898, train_loss: 0.21877456, train_accuracy: 0.9297, test_Accuracy: 0.9353\n",
            "Epoch: [ 0] [  203/  468] time: 54.7290, train_loss: 0.20373535, train_accuracy: 0.9219, test_Accuracy: 0.9357\n",
            "Epoch: [ 0] [  204/  468] time: 55.0839, train_loss: 0.19320782, train_accuracy: 0.9688, test_Accuracy: 0.9347\n",
            "Epoch: [ 0] [  205/  468] time: 55.3298, train_loss: 0.19223738, train_accuracy: 0.9375, test_Accuracy: 0.9357\n",
            "Epoch: [ 0] [  206/  468] time: 55.5553, train_loss: 0.15445143, train_accuracy: 0.9453, test_Accuracy: 0.9357\n",
            "Epoch: [ 0] [  207/  468] time: 55.7901, train_loss: 0.25911120, train_accuracy: 0.9297, test_Accuracy: 0.9358\n",
            "Epoch: [ 0] [  208/  468] time: 56.0288, train_loss: 0.21533222, train_accuracy: 0.9375, test_Accuracy: 0.9382\n",
            "Epoch: [ 0] [  209/  468] time: 56.2875, train_loss: 0.23381075, train_accuracy: 0.9219, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  210/  468] time: 56.5243, train_loss: 0.11885743, train_accuracy: 0.9766, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  211/  468] time: 56.7601, train_loss: 0.14123198, train_accuracy: 0.9688, test_Accuracy: 0.9384\n",
            "Epoch: [ 0] [  212/  468] time: 57.0030, train_loss: 0.15481757, train_accuracy: 0.9609, test_Accuracy: 0.9355\n",
            "Epoch: [ 0] [  213/  468] time: 57.2487, train_loss: 0.26096159, train_accuracy: 0.9062, test_Accuracy: 0.9341\n",
            "Epoch: [ 0] [  214/  468] time: 57.4942, train_loss: 0.12230184, train_accuracy: 0.9609, test_Accuracy: 0.9346\n",
            "Epoch: [ 0] [  215/  468] time: 57.7267, train_loss: 0.23645619, train_accuracy: 0.9219, test_Accuracy: 0.9361\n",
            "Epoch: [ 0] [  216/  468] time: 57.9647, train_loss: 0.16057910, train_accuracy: 0.9453, test_Accuracy: 0.9376\n",
            "Epoch: [ 0] [  217/  468] time: 58.2173, train_loss: 0.13406871, train_accuracy: 0.9531, test_Accuracy: 0.9403\n",
            "Epoch: [ 0] [  218/  468] time: 58.4479, train_loss: 0.12739494, train_accuracy: 0.9609, test_Accuracy: 0.9414\n",
            "Epoch: [ 0] [  219/  468] time: 58.8113, train_loss: 0.17204341, train_accuracy: 0.9453, test_Accuracy: 0.9402\n",
            "Epoch: [ 0] [  220/  468] time: 59.0447, train_loss: 0.15589401, train_accuracy: 0.9531, test_Accuracy: 0.9399\n",
            "Epoch: [ 0] [  221/  468] time: 59.3027, train_loss: 0.27822864, train_accuracy: 0.9219, test_Accuracy: 0.9410\n",
            "Epoch: [ 0] [  222/  468] time: 59.5285, train_loss: 0.11582641, train_accuracy: 0.9609, test_Accuracy: 0.9419\n",
            "Epoch: [ 0] [  223/  468] time: 59.7722, train_loss: 0.23586690, train_accuracy: 0.9453, test_Accuracy: 0.9428\n",
            "Epoch: [ 0] [  224/  468] time: 60.0128, train_loss: 0.32626373, train_accuracy: 0.8828, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  225/  468] time: 60.3706, train_loss: 0.25692356, train_accuracy: 0.9453, test_Accuracy: 0.9422\n",
            "Epoch: [ 0] [  226/  468] time: 60.6169, train_loss: 0.14760716, train_accuracy: 0.9531, test_Accuracy: 0.9407\n",
            "Epoch: [ 0] [  227/  468] time: 60.8495, train_loss: 0.32122809, train_accuracy: 0.9062, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  228/  468] time: 61.0832, train_loss: 0.17311874, train_accuracy: 0.9531, test_Accuracy: 0.9387\n",
            "Epoch: [ 0] [  229/  468] time: 61.3338, train_loss: 0.10844615, train_accuracy: 0.9453, test_Accuracy: 0.9391\n",
            "Epoch: [ 0] [  230/  468] time: 61.5941, train_loss: 0.27648616, train_accuracy: 0.9141, test_Accuracy: 0.9400\n",
            "Epoch: [ 0] [  231/  468] time: 61.8266, train_loss: 0.26242107, train_accuracy: 0.9219, test_Accuracy: 0.9398\n",
            "Epoch: [ 0] [  232/  468] time: 62.0576, train_loss: 0.31103459, train_accuracy: 0.9141, test_Accuracy: 0.9396\n",
            "Epoch: [ 0] [  233/  468] time: 62.3171, train_loss: 0.15903175, train_accuracy: 0.9609, test_Accuracy: 0.9410\n",
            "Epoch: [ 0] [  234/  468] time: 62.5461, train_loss: 0.12185561, train_accuracy: 0.9453, test_Accuracy: 0.9413\n",
            "Epoch: [ 0] [  235/  468] time: 62.7918, train_loss: 0.13111378, train_accuracy: 0.9375, test_Accuracy: 0.9419\n",
            "Epoch: [ 0] [  236/  468] time: 63.0287, train_loss: 0.13242774, train_accuracy: 0.9609, test_Accuracy: 0.9442\n",
            "Epoch: [ 0] [  237/  468] time: 63.3879, train_loss: 0.18840489, train_accuracy: 0.9219, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  238/  468] time: 63.6236, train_loss: 0.22594200, train_accuracy: 0.9375, test_Accuracy: 0.9444\n",
            "Epoch: [ 0] [  239/  468] time: 63.8750, train_loss: 0.26842579, train_accuracy: 0.9531, test_Accuracy: 0.9416\n",
            "Epoch: [ 0] [  240/  468] time: 64.1142, train_loss: 0.14159071, train_accuracy: 0.9609, test_Accuracy: 0.9408\n",
            "Epoch: [ 0] [  241/  468] time: 64.4700, train_loss: 0.14619105, train_accuracy: 0.9375, test_Accuracy: 0.9401\n",
            "Epoch: [ 0] [  242/  468] time: 64.7155, train_loss: 0.17068525, train_accuracy: 0.9609, test_Accuracy: 0.9417\n",
            "Epoch: [ 0] [  243/  468] time: 64.9423, train_loss: 0.18548359, train_accuracy: 0.9453, test_Accuracy: 0.9430\n",
            "Epoch: [ 0] [  244/  468] time: 65.1699, train_loss: 0.19213648, train_accuracy: 0.9453, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  245/  468] time: 65.4138, train_loss: 0.30445063, train_accuracy: 0.9453, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  246/  468] time: 65.6463, train_loss: 0.14924100, train_accuracy: 0.9531, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  247/  468] time: 65.8900, train_loss: 0.11627872, train_accuracy: 0.9766, test_Accuracy: 0.9479\n",
            "Epoch: [ 0] [  248/  468] time: 66.1166, train_loss: 0.13381933, train_accuracy: 0.9531, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  249/  468] time: 66.3553, train_loss: 0.21398932, train_accuracy: 0.9453, test_Accuracy: 0.9470\n",
            "Epoch: [ 0] [  250/  468] time: 66.6109, train_loss: 0.15115058, train_accuracy: 0.9609, test_Accuracy: 0.9476\n",
            "Epoch: [ 0] [  251/  468] time: 66.8401, train_loss: 0.16848585, train_accuracy: 0.9453, test_Accuracy: 0.9463\n",
            "Epoch: [ 0] [  252/  468] time: 67.0657, train_loss: 0.23260678, train_accuracy: 0.9297, test_Accuracy: 0.9452\n",
            "Epoch: [ 0] [  253/  468] time: 67.2959, train_loss: 0.17515132, train_accuracy: 0.9609, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  254/  468] time: 67.5393, train_loss: 0.10485495, train_accuracy: 0.9766, test_Accuracy: 0.9457\n",
            "Epoch: [ 0] [  255/  468] time: 67.7782, train_loss: 0.15510079, train_accuracy: 0.9453, test_Accuracy: 0.9469\n",
            "Epoch: [ 0] [  256/  468] time: 68.0152, train_loss: 0.32560083, train_accuracy: 0.9219, test_Accuracy: 0.9467\n",
            "Epoch: [ 0] [  257/  468] time: 68.2494, train_loss: 0.13876863, train_accuracy: 0.9609, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  258/  468] time: 68.4943, train_loss: 0.18846776, train_accuracy: 0.9531, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  259/  468] time: 68.7267, train_loss: 0.20056185, train_accuracy: 0.9375, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  260/  468] time: 68.9596, train_loss: 0.17085332, train_accuracy: 0.9375, test_Accuracy: 0.9484\n",
            "Epoch: [ 0] [  261/  468] time: 69.1935, train_loss: 0.16523401, train_accuracy: 0.9453, test_Accuracy: 0.9487\n",
            "Epoch: [ 0] [  262/  468] time: 69.4230, train_loss: 0.13503881, train_accuracy: 0.9688, test_Accuracy: 0.9483\n",
            "Epoch: [ 0] [  263/  468] time: 69.6726, train_loss: 0.15992728, train_accuracy: 0.9453, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  264/  468] time: 69.9123, train_loss: 0.10797103, train_accuracy: 0.9609, test_Accuracy: 0.9465\n",
            "Epoch: [ 0] [  265/  468] time: 70.1548, train_loss: 0.08599527, train_accuracy: 0.9922, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  266/  468] time: 70.4025, train_loss: 0.18049121, train_accuracy: 0.9297, test_Accuracy: 0.9440\n",
            "Epoch: [ 0] [  267/  468] time: 70.6438, train_loss: 0.26049885, train_accuracy: 0.9375, test_Accuracy: 0.9426\n",
            "Epoch: [ 0] [  268/  468] time: 70.8758, train_loss: 0.11519691, train_accuracy: 0.9688, test_Accuracy: 0.9417\n",
            "Epoch: [ 0] [  269/  468] time: 71.1063, train_loss: 0.11846213, train_accuracy: 0.9531, test_Accuracy: 0.9410\n",
            "Epoch: [ 0] [  270/  468] time: 71.3449, train_loss: 0.16441189, train_accuracy: 0.9766, test_Accuracy: 0.9394\n",
            "Epoch: [ 0] [  271/  468] time: 71.5962, train_loss: 0.12364296, train_accuracy: 0.9531, test_Accuracy: 0.9369\n",
            "Epoch: [ 0] [  272/  468] time: 71.9548, train_loss: 0.13673656, train_accuracy: 0.9531, test_Accuracy: 0.9397\n",
            "Epoch: [ 0] [  273/  468] time: 72.1861, train_loss: 0.21171004, train_accuracy: 0.9219, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  274/  468] time: 72.4286, train_loss: 0.16917932, train_accuracy: 0.9453, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  275/  468] time: 72.6770, train_loss: 0.18703967, train_accuracy: 0.9453, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  276/  468] time: 72.9055, train_loss: 0.15430126, train_accuracy: 0.9609, test_Accuracy: 0.9496\n",
            "Epoch: [ 0] [  277/  468] time: 73.1351, train_loss: 0.13605785, train_accuracy: 0.9531, test_Accuracy: 0.9492\n",
            "Epoch: [ 0] [  278/  468] time: 73.3742, train_loss: 0.10138488, train_accuracy: 0.9844, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  279/  468] time: 73.6379, train_loss: 0.19846112, train_accuracy: 0.9141, test_Accuracy: 0.9448\n",
            "Epoch: [ 0] [  280/  468] time: 73.8773, train_loss: 0.19617091, train_accuracy: 0.9375, test_Accuracy: 0.9434\n",
            "Epoch: [ 0] [  281/  468] time: 74.1058, train_loss: 0.23703991, train_accuracy: 0.9375, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  282/  468] time: 74.3470, train_loss: 0.18454185, train_accuracy: 0.9688, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  283/  468] time: 74.6106, train_loss: 0.18348725, train_accuracy: 0.9453, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  284/  468] time: 74.8388, train_loss: 0.18227372, train_accuracy: 0.9375, test_Accuracy: 0.9475\n",
            "Epoch: [ 0] [  285/  468] time: 75.0649, train_loss: 0.21958533, train_accuracy: 0.9453, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  286/  468] time: 75.2980, train_loss: 0.15798093, train_accuracy: 0.9609, test_Accuracy: 0.9441\n",
            "Epoch: [ 0] [  287/  468] time: 75.5330, train_loss: 0.14758720, train_accuracy: 0.9531, test_Accuracy: 0.9424\n",
            "Epoch: [ 0] [  288/  468] time: 75.7674, train_loss: 0.08970615, train_accuracy: 0.9844, test_Accuracy: 0.9417\n",
            "Epoch: [ 0] [  289/  468] time: 76.0015, train_loss: 0.17837155, train_accuracy: 0.9453, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  290/  468] time: 76.2325, train_loss: 0.23569110, train_accuracy: 0.9453, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  291/  468] time: 76.4662, train_loss: 0.14597782, train_accuracy: 0.9375, test_Accuracy: 0.9458\n",
            "Epoch: [ 0] [  292/  468] time: 76.7368, train_loss: 0.12554301, train_accuracy: 0.9609, test_Accuracy: 0.9456\n",
            "Epoch: [ 0] [  293/  468] time: 76.9711, train_loss: 0.08987826, train_accuracy: 0.9688, test_Accuracy: 0.9450\n",
            "Epoch: [ 0] [  294/  468] time: 77.2097, train_loss: 0.11454307, train_accuracy: 0.9609, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  295/  468] time: 77.4495, train_loss: 0.15516639, train_accuracy: 0.9453, test_Accuracy: 0.9462\n",
            "Epoch: [ 0] [  296/  468] time: 77.6912, train_loss: 0.22186789, train_accuracy: 0.9453, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  297/  468] time: 77.9227, train_loss: 0.12446707, train_accuracy: 0.9609, test_Accuracy: 0.9480\n",
            "Epoch: [ 0] [  298/  468] time: 78.1474, train_loss: 0.13473240, train_accuracy: 0.9688, test_Accuracy: 0.9459\n",
            "Epoch: [ 0] [  299/  468] time: 78.3699, train_loss: 0.06784647, train_accuracy: 0.9844, test_Accuracy: 0.9447\n",
            "Epoch: [ 0] [  300/  468] time: 78.6065, train_loss: 0.26966447, train_accuracy: 0.8906, test_Accuracy: 0.9429\n",
            "Epoch: [ 0] [  301/  468] time: 78.8409, train_loss: 0.19199565, train_accuracy: 0.9453, test_Accuracy: 0.9420\n",
            "Epoch: [ 0] [  302/  468] time: 79.0744, train_loss: 0.25791493, train_accuracy: 0.8984, test_Accuracy: 0.9438\n",
            "Epoch: [ 0] [  303/  468] time: 79.3075, train_loss: 0.14068323, train_accuracy: 0.9688, test_Accuracy: 0.9468\n",
            "Epoch: [ 0] [  304/  468] time: 79.5462, train_loss: 0.13797285, train_accuracy: 0.9219, test_Accuracy: 0.9478\n",
            "Epoch: [ 0] [  305/  468] time: 79.9120, train_loss: 0.18639751, train_accuracy: 0.9609, test_Accuracy: 0.9474\n",
            "Epoch: [ 0] [  306/  468] time: 80.1391, train_loss: 0.16928539, train_accuracy: 0.9453, test_Accuracy: 0.9477\n",
            "Epoch: [ 0] [  307/  468] time: 80.3770, train_loss: 0.25041151, train_accuracy: 0.9375, test_Accuracy: 0.9481\n",
            "Epoch: [ 0] [  308/  468] time: 80.6184, train_loss: 0.16209581, train_accuracy: 0.9609, test_Accuracy: 0.9466\n",
            "Epoch: [ 0] [  309/  468] time: 80.8663, train_loss: 0.20512956, train_accuracy: 0.9453, test_Accuracy: 0.9455\n",
            "Epoch: [ 0] [  310/  468] time: 81.1053, train_loss: 0.15542465, train_accuracy: 0.9531, test_Accuracy: 0.9439\n",
            "Epoch: [ 0] [  311/  468] time: 81.3438, train_loss: 0.12817147, train_accuracy: 0.9609, test_Accuracy: 0.9427\n",
            "Epoch: [ 0] [  312/  468] time: 81.5877, train_loss: 0.09640759, train_accuracy: 0.9609, test_Accuracy: 0.9435\n",
            "Epoch: [ 0] [  313/  468] time: 81.8391, train_loss: 0.20038059, train_accuracy: 0.9297, test_Accuracy: 0.9460\n",
            "Epoch: [ 0] [  314/  468] time: 82.0759, train_loss: 0.17917813, train_accuracy: 0.9531, test_Accuracy: 0.9495\n",
            "Epoch: [ 0] [  315/  468] time: 82.3039, train_loss: 0.15925562, train_accuracy: 0.9688, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  316/  468] time: 82.6681, train_loss: 0.12142507, train_accuracy: 0.9766, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  317/  468] time: 82.9096, train_loss: 0.20295626, train_accuracy: 0.9453, test_Accuracy: 0.9521\n",
            "Epoch: [ 0] [  318/  468] time: 83.1478, train_loss: 0.10258804, train_accuracy: 0.9609, test_Accuracy: 0.9521\n",
            "Epoch: [ 0] [  319/  468] time: 83.3809, train_loss: 0.18087146, train_accuracy: 0.9297, test_Accuracy: 0.9515\n",
            "Epoch: [ 0] [  320/  468] time: 83.6221, train_loss: 0.18652609, train_accuracy: 0.9375, test_Accuracy: 0.9510\n",
            "Epoch: [ 0] [  321/  468] time: 83.9816, train_loss: 0.15076336, train_accuracy: 0.9609, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  322/  468] time: 84.2187, train_loss: 0.15857929, train_accuracy: 0.9609, test_Accuracy: 0.9534\n",
            "Epoch: [ 0] [  323/  468] time: 84.4577, train_loss: 0.18019789, train_accuracy: 0.9531, test_Accuracy: 0.9537\n",
            "Epoch: [ 0] [  324/  468] time: 84.7011, train_loss: 0.14909804, train_accuracy: 0.9453, test_Accuracy: 0.9525\n",
            "Epoch: [ 0] [  325/  468] time: 84.9469, train_loss: 0.15695354, train_accuracy: 0.9453, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  326/  468] time: 85.1976, train_loss: 0.24372417, train_accuracy: 0.9375, test_Accuracy: 0.9491\n",
            "Epoch: [ 0] [  327/  468] time: 85.4358, train_loss: 0.22955370, train_accuracy: 0.9062, test_Accuracy: 0.9485\n",
            "Epoch: [ 0] [  328/  468] time: 85.8006, train_loss: 0.19571048, train_accuracy: 0.9375, test_Accuracy: 0.9461\n",
            "Epoch: [ 0] [  329/  468] time: 86.0319, train_loss: 0.22991896, train_accuracy: 0.9219, test_Accuracy: 0.9499\n",
            "Epoch: [ 0] [  330/  468] time: 86.2876, train_loss: 0.11070358, train_accuracy: 0.9688, test_Accuracy: 0.9516\n",
            "Epoch: [ 0] [  331/  468] time: 86.6455, train_loss: 0.08991517, train_accuracy: 0.9844, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  332/  468] time: 86.8911, train_loss: 0.19026197, train_accuracy: 0.9531, test_Accuracy: 0.9547\n",
            "Epoch: [ 0] [  333/  468] time: 87.1227, train_loss: 0.08963263, train_accuracy: 0.9766, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  334/  468] time: 87.3636, train_loss: 0.16881938, train_accuracy: 0.9609, test_Accuracy: 0.9525\n",
            "Epoch: [ 0] [  335/  468] time: 87.7201, train_loss: 0.13629624, train_accuracy: 0.9531, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  336/  468] time: 88.0905, train_loss: 0.14258125, train_accuracy: 0.9609, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  337/  468] time: 88.3235, train_loss: 0.10904852, train_accuracy: 0.9688, test_Accuracy: 0.9501\n",
            "Epoch: [ 0] [  338/  468] time: 88.5582, train_loss: 0.10537413, train_accuracy: 0.9609, test_Accuracy: 0.9499\n",
            "Epoch: [ 0] [  339/  468] time: 88.7958, train_loss: 0.10679984, train_accuracy: 0.9688, test_Accuracy: 0.9509\n",
            "Epoch: [ 0] [  340/  468] time: 89.0430, train_loss: 0.13387659, train_accuracy: 0.9609, test_Accuracy: 0.9522\n",
            "Epoch: [ 0] [  341/  468] time: 89.2715, train_loss: 0.12159260, train_accuracy: 0.9375, test_Accuracy: 0.9535\n",
            "Epoch: [ 0] [  342/  468] time: 89.5037, train_loss: 0.16173503, train_accuracy: 0.9453, test_Accuracy: 0.9546\n",
            "Epoch: [ 0] [  343/  468] time: 89.7367, train_loss: 0.08637686, train_accuracy: 0.9844, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  344/  468] time: 89.9722, train_loss: 0.16660950, train_accuracy: 0.9531, test_Accuracy: 0.9548\n",
            "Epoch: [ 0] [  345/  468] time: 90.2134, train_loss: 0.17356522, train_accuracy: 0.9688, test_Accuracy: 0.9530\n",
            "Epoch: [ 0] [  346/  468] time: 90.4759, train_loss: 0.10644510, train_accuracy: 0.9609, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  347/  468] time: 90.7133, train_loss: 0.11981557, train_accuracy: 0.9609, test_Accuracy: 0.9511\n",
            "Epoch: [ 0] [  348/  468] time: 91.0746, train_loss: 0.18410948, train_accuracy: 0.9375, test_Accuracy: 0.9510\n",
            "Epoch: [ 0] [  349/  468] time: 91.3087, train_loss: 0.24688867, train_accuracy: 0.9297, test_Accuracy: 0.9504\n",
            "Epoch: [ 0] [  350/  468] time: 91.5401, train_loss: 0.06461023, train_accuracy: 0.9766, test_Accuracy: 0.9504\n",
            "Epoch: [ 0] [  351/  468] time: 91.7690, train_loss: 0.07047160, train_accuracy: 0.9688, test_Accuracy: 0.9489\n",
            "Epoch: [ 0] [  352/  468] time: 91.9938, train_loss: 0.26298276, train_accuracy: 0.9453, test_Accuracy: 0.9505\n",
            "Epoch: [ 0] [  353/  468] time: 92.2300, train_loss: 0.09245349, train_accuracy: 0.9766, test_Accuracy: 0.9517\n",
            "Epoch: [ 0] [  354/  468] time: 92.4625, train_loss: 0.09836705, train_accuracy: 0.9688, test_Accuracy: 0.9526\n",
            "Epoch: [ 0] [  355/  468] time: 92.6936, train_loss: 0.21949317, train_accuracy: 0.9219, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  356/  468] time: 92.9379, train_loss: 0.10662623, train_accuracy: 0.9766, test_Accuracy: 0.9540\n",
            "Epoch: [ 0] [  357/  468] time: 93.1739, train_loss: 0.13105446, train_accuracy: 0.9531, test_Accuracy: 0.9554\n",
            "Epoch: [ 0] [  358/  468] time: 93.4105, train_loss: 0.13669625, train_accuracy: 0.9531, test_Accuracy: 0.9553\n",
            "Epoch: [ 0] [  359/  468] time: 93.6381, train_loss: 0.10621049, train_accuracy: 0.9766, test_Accuracy: 0.9536\n",
            "Epoch: [ 0] [  360/  468] time: 93.8678, train_loss: 0.05591458, train_accuracy: 0.9922, test_Accuracy: 0.9528\n",
            "Epoch: [ 0] [  361/  468] time: 94.0948, train_loss: 0.13672319, train_accuracy: 0.9453, test_Accuracy: 0.9524\n",
            "Epoch: [ 0] [  362/  468] time: 94.3347, train_loss: 0.19516978, train_accuracy: 0.9453, test_Accuracy: 0.9518\n",
            "Epoch: [ 0] [  363/  468] time: 94.5633, train_loss: 0.15818678, train_accuracy: 0.9609, test_Accuracy: 0.9506\n",
            "Epoch: [ 0] [  364/  468] time: 94.8024, train_loss: 0.12112126, train_accuracy: 0.9688, test_Accuracy: 0.9508\n",
            "Epoch: [ 0] [  365/  468] time: 95.0296, train_loss: 0.15350860, train_accuracy: 0.9453, test_Accuracy: 0.9504\n",
            "Epoch: [ 0] [  366/  468] time: 95.2566, train_loss: 0.14956205, train_accuracy: 0.9609, test_Accuracy: 0.9513\n",
            "Epoch: [ 0] [  367/  468] time: 95.5167, train_loss: 0.23229036, train_accuracy: 0.9219, test_Accuracy: 0.9523\n",
            "Epoch: [ 0] [  368/  468] time: 95.7381, train_loss: 0.13429219, train_accuracy: 0.9453, test_Accuracy: 0.9531\n",
            "Epoch: [ 0] [  369/  468] time: 95.9670, train_loss: 0.13847244, train_accuracy: 0.9609, test_Accuracy: 0.9541\n",
            "Epoch: [ 0] [  370/  468] time: 96.3219, train_loss: 0.09388869, train_accuracy: 0.9688, test_Accuracy: 0.9546\n",
            "Epoch: [ 0] [  371/  468] time: 96.6767, train_loss: 0.22628012, train_accuracy: 0.9375, test_Accuracy: 0.9542\n",
            "Epoch: [ 0] [  372/  468] time: 96.9106, train_loss: 0.15178421, train_accuracy: 0.9688, test_Accuracy: 0.9555\n",
            "Epoch: [ 0] [  373/  468] time: 97.1335, train_loss: 0.12605914, train_accuracy: 0.9375, test_Accuracy: 0.9551\n",
            "Epoch: [ 0] [  374/  468] time: 97.3668, train_loss: 0.14795658, train_accuracy: 0.9609, test_Accuracy: 0.9543\n",
            "Epoch: [ 0] [  375/  468] time: 97.5900, train_loss: 0.25563380, train_accuracy: 0.9375, test_Accuracy: 0.9537\n",
            "Epoch: [ 0] [  376/  468] time: 97.8263, train_loss: 0.10257398, train_accuracy: 0.9609, test_Accuracy: 0.9533\n",
            "Epoch: [ 0] [  377/  468] time: 98.0560, train_loss: 0.22159365, train_accuracy: 0.9297, test_Accuracy: 0.9539\n",
            "Epoch: [ 0] [  378/  468] time: 98.3045, train_loss: 0.13768601, train_accuracy: 0.9609, test_Accuracy: 0.9550\n",
            "Epoch: [ 0] [  379/  468] time: 98.5381, train_loss: 0.16981369, train_accuracy: 0.9531, test_Accuracy: 0.9568\n",
            "Epoch: [ 0] [  380/  468] time: 98.7657, train_loss: 0.13565379, train_accuracy: 0.9609, test_Accuracy: 0.9574\n",
            "Epoch: [ 0] [  381/  468] time: 98.9866, train_loss: 0.21117997, train_accuracy: 0.9297, test_Accuracy: 0.9576\n",
            "Epoch: [ 0] [  382/  468] time: 99.2156, train_loss: 0.12126553, train_accuracy: 0.9531, test_Accuracy: 0.9578\n",
            "Epoch: [ 0] [  383/  468] time: 99.4612, train_loss: 0.19374421, train_accuracy: 0.9297, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  384/  468] time: 99.6986, train_loss: 0.09163804, train_accuracy: 0.9688, test_Accuracy: 0.9579\n",
            "Epoch: [ 0] [  385/  468] time: 99.9332, train_loss: 0.13441594, train_accuracy: 0.9531, test_Accuracy: 0.9571\n",
            "Epoch: [ 0] [  386/  468] time: 100.2941, train_loss: 0.17241633, train_accuracy: 0.9375, test_Accuracy: 0.9579\n",
            "Epoch: [ 0] [  387/  468] time: 100.5224, train_loss: 0.14864357, train_accuracy: 0.9531, test_Accuracy: 0.9577\n",
            "Epoch: [ 0] [  388/  468] time: 100.7558, train_loss: 0.17500395, train_accuracy: 0.9609, test_Accuracy: 0.9582\n",
            "Epoch: [ 0] [  389/  468] time: 100.9798, train_loss: 0.10869024, train_accuracy: 0.9531, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  390/  468] time: 101.2048, train_loss: 0.23595101, train_accuracy: 0.9531, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  391/  468] time: 101.4498, train_loss: 0.23157638, train_accuracy: 0.9375, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  392/  468] time: 101.6774, train_loss: 0.07335254, train_accuracy: 0.9844, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  393/  468] time: 101.9177, train_loss: 0.18308777, train_accuracy: 0.9297, test_Accuracy: 0.9580\n",
            "Epoch: [ 0] [  394/  468] time: 102.1504, train_loss: 0.22177829, train_accuracy: 0.9766, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  395/  468] time: 102.5071, train_loss: 0.16842505, train_accuracy: 0.9531, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  396/  468] time: 102.7384, train_loss: 0.21804531, train_accuracy: 0.9531, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  397/  468] time: 102.9571, train_loss: 0.17954579, train_accuracy: 0.9609, test_Accuracy: 0.9589\n",
            "Epoch: [ 0] [  398/  468] time: 103.1847, train_loss: 0.08879717, train_accuracy: 0.9688, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  399/  468] time: 103.4242, train_loss: 0.16848291, train_accuracy: 0.9453, test_Accuracy: 0.9602\n",
            "Epoch: [ 0] [  400/  468] time: 103.6554, train_loss: 0.18894279, train_accuracy: 0.9531, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  401/  468] time: 103.8820, train_loss: 0.13850395, train_accuracy: 0.9766, test_Accuracy: 0.9608\n",
            "Epoch: [ 0] [  402/  468] time: 104.1147, train_loss: 0.17669238, train_accuracy: 0.9297, test_Accuracy: 0.9595\n",
            "Epoch: [ 0] [  403/  468] time: 104.3457, train_loss: 0.15500253, train_accuracy: 0.9609, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  404/  468] time: 104.5855, train_loss: 0.12125689, train_accuracy: 0.9609, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  405/  468] time: 104.8119, train_loss: 0.05826066, train_accuracy: 1.0000, test_Accuracy: 0.9599\n",
            "Epoch: [ 0] [  406/  468] time: 105.0397, train_loss: 0.11787198, train_accuracy: 0.9609, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  407/  468] time: 105.2657, train_loss: 0.13509065, train_accuracy: 0.9609, test_Accuracy: 0.9604\n",
            "Epoch: [ 0] [  408/  468] time: 105.5008, train_loss: 0.09385619, train_accuracy: 0.9844, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  409/  468] time: 105.7444, train_loss: 0.15237209, train_accuracy: 0.9453, test_Accuracy: 0.9630\n",
            "Epoch: [ 0] [  410/  468] time: 105.9789, train_loss: 0.10047598, train_accuracy: 0.9688, test_Accuracy: 0.9642\n",
            "Epoch: [ 0] [  411/  468] time: 106.2069, train_loss: 0.07175207, train_accuracy: 0.9766, test_Accuracy: 0.9641\n",
            "Epoch: [ 0] [  412/  468] time: 106.4646, train_loss: 0.10671438, train_accuracy: 0.9766, test_Accuracy: 0.9633\n",
            "Epoch: [ 0] [  413/  468] time: 106.6947, train_loss: 0.11814959, train_accuracy: 0.9766, test_Accuracy: 0.9627\n",
            "Epoch: [ 0] [  414/  468] time: 106.9185, train_loss: 0.09238496, train_accuracy: 0.9922, test_Accuracy: 0.9614\n",
            "Epoch: [ 0] [  415/  468] time: 107.1550, train_loss: 0.16486511, train_accuracy: 0.9531, test_Accuracy: 0.9607\n",
            "Epoch: [ 0] [  416/  468] time: 107.3790, train_loss: 0.10576309, train_accuracy: 0.9688, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  417/  468] time: 107.6345, train_loss: 0.11884308, train_accuracy: 0.9531, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  418/  468] time: 107.8637, train_loss: 0.26729321, train_accuracy: 0.9219, test_Accuracy: 0.9620\n",
            "Epoch: [ 0] [  419/  468] time: 108.0878, train_loss: 0.10313089, train_accuracy: 0.9844, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  420/  468] time: 108.3205, train_loss: 0.11264066, train_accuracy: 0.9688, test_Accuracy: 0.9618\n",
            "Epoch: [ 0] [  421/  468] time: 108.5625, train_loss: 0.07896185, train_accuracy: 0.9766, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  422/  468] time: 108.7885, train_loss: 0.09839821, train_accuracy: 0.9688, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  423/  468] time: 109.0269, train_loss: 0.13610093, train_accuracy: 0.9609, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  424/  468] time: 109.2573, train_loss: 0.11517014, train_accuracy: 0.9688, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  425/  468] time: 109.4925, train_loss: 0.19815651, train_accuracy: 0.9375, test_Accuracy: 0.9598\n",
            "Epoch: [ 0] [  426/  468] time: 109.8632, train_loss: 0.08347116, train_accuracy: 0.9844, test_Accuracy: 0.9606\n",
            "Epoch: [ 0] [  427/  468] time: 110.0984, train_loss: 0.13117400, train_accuracy: 0.9688, test_Accuracy: 0.9626\n",
            "Epoch: [ 0] [  428/  468] time: 110.3293, train_loss: 0.12049790, train_accuracy: 0.9453, test_Accuracy: 0.9628\n",
            "Epoch: [ 0] [  429/  468] time: 110.5705, train_loss: 0.11326557, train_accuracy: 0.9609, test_Accuracy: 0.9625\n",
            "Epoch: [ 0] [  430/  468] time: 110.9357, train_loss: 0.19160512, train_accuracy: 0.9531, test_Accuracy: 0.9629\n",
            "Epoch: [ 0] [  431/  468] time: 111.1714, train_loss: 0.13947126, train_accuracy: 0.9609, test_Accuracy: 0.9615\n",
            "Epoch: [ 0] [  432/  468] time: 111.4129, train_loss: 0.13611919, train_accuracy: 0.9609, test_Accuracy: 0.9613\n",
            "Epoch: [ 0] [  433/  468] time: 111.6621, train_loss: 0.08629853, train_accuracy: 0.9844, test_Accuracy: 0.9603\n",
            "Epoch: [ 0] [  434/  468] time: 111.9077, train_loss: 0.11436498, train_accuracy: 0.9609, test_Accuracy: 0.9592\n",
            "Epoch: [ 0] [  435/  468] time: 112.1367, train_loss: 0.10183682, train_accuracy: 0.9688, test_Accuracy: 0.9596\n",
            "Epoch: [ 0] [  436/  468] time: 112.3759, train_loss: 0.14373510, train_accuracy: 0.9609, test_Accuracy: 0.9593\n",
            "Epoch: [ 0] [  437/  468] time: 112.6130, train_loss: 0.17959751, train_accuracy: 0.9375, test_Accuracy: 0.9587\n",
            "Epoch: [ 0] [  438/  468] time: 112.8569, train_loss: 0.29760391, train_accuracy: 0.9297, test_Accuracy: 0.9588\n",
            "Epoch: [ 0] [  439/  468] time: 113.0885, train_loss: 0.11146409, train_accuracy: 0.9766, test_Accuracy: 0.9583\n",
            "Epoch: [ 0] [  440/  468] time: 113.3301, train_loss: 0.09246446, train_accuracy: 0.9688, test_Accuracy: 0.9575\n",
            "Epoch: [ 0] [  441/  468] time: 113.5640, train_loss: 0.29696870, train_accuracy: 0.9297, test_Accuracy: 0.9584\n",
            "Epoch: [ 0] [  442/  468] time: 113.8032, train_loss: 0.10036325, train_accuracy: 0.9766, test_Accuracy: 0.9594\n",
            "Epoch: [ 0] [  443/  468] time: 114.0435, train_loss: 0.22495873, train_accuracy: 0.9219, test_Accuracy: 0.9624\n",
            "Epoch: [ 0] [  444/  468] time: 114.3983, train_loss: 0.16636318, train_accuracy: 0.9531, test_Accuracy: 0.9639\n",
            "Epoch: [ 0] [  445/  468] time: 114.6284, train_loss: 0.05407621, train_accuracy: 1.0000, test_Accuracy: 0.9639\n",
            "Epoch: [ 0] [  446/  468] time: 114.8769, train_loss: 0.09430943, train_accuracy: 0.9688, test_Accuracy: 0.9630\n",
            "Epoch: [ 0] [  447/  468] time: 115.1080, train_loss: 0.11245754, train_accuracy: 0.9844, test_Accuracy: 0.9619\n",
            "Epoch: [ 0] [  448/  468] time: 115.3413, train_loss: 0.12730080, train_accuracy: 0.9531, test_Accuracy: 0.9616\n",
            "Epoch: [ 0] [  449/  468] time: 115.5810, train_loss: 0.21970451, train_accuracy: 0.9531, test_Accuracy: 0.9626\n",
            "Epoch: [ 0] [  450/  468] time: 115.8199, train_loss: 0.11185613, train_accuracy: 0.9375, test_Accuracy: 0.9639\n",
            "Epoch: [ 0] [  451/  468] time: 116.0774, train_loss: 0.11694875, train_accuracy: 0.9609, test_Accuracy: 0.9638\n",
            "Epoch: [ 0] [  452/  468] time: 116.3189, train_loss: 0.09615501, train_accuracy: 0.9766, test_Accuracy: 0.9640\n",
            "Epoch: [ 0] [  453/  468] time: 116.5555, train_loss: 0.07349722, train_accuracy: 0.9688, test_Accuracy: 0.9631\n",
            "Epoch: [ 0] [  454/  468] time: 116.8023, train_loss: 0.14363293, train_accuracy: 0.9609, test_Accuracy: 0.9630\n",
            "Epoch: [ 0] [  455/  468] time: 117.0326, train_loss: 0.11866643, train_accuracy: 0.9766, test_Accuracy: 0.9622\n",
            "Epoch: [ 0] [  456/  468] time: 117.2614, train_loss: 0.15058665, train_accuracy: 0.9531, test_Accuracy: 0.9626\n",
            "Epoch: [ 0] [  457/  468] time: 117.4899, train_loss: 0.09257489, train_accuracy: 0.9766, test_Accuracy: 0.9633\n",
            "Epoch: [ 0] [  458/  468] time: 117.8516, train_loss: 0.14307952, train_accuracy: 0.9531, test_Accuracy: 0.9629\n",
            "Epoch: [ 0] [  459/  468] time: 118.0830, train_loss: 0.17183998, train_accuracy: 0.9531, test_Accuracy: 0.9631\n",
            "Epoch: [ 0] [  460/  468] time: 118.3218, train_loss: 0.18813503, train_accuracy: 0.9453, test_Accuracy: 0.9650\n",
            "Epoch: [ 0] [  461/  468] time: 118.5606, train_loss: 0.10143172, train_accuracy: 0.9766, test_Accuracy: 0.9647\n",
            "Epoch: [ 0] [  462/  468] time: 118.8064, train_loss: 0.10872839, train_accuracy: 0.9375, test_Accuracy: 0.9635\n",
            "Epoch: [ 0] [  463/  468] time: 119.0393, train_loss: 0.08694249, train_accuracy: 0.9609, test_Accuracy: 0.9607\n",
            "Epoch: [ 0] [  464/  468] time: 119.2767, train_loss: 0.05331102, train_accuracy: 0.9922, test_Accuracy: 0.9591\n",
            "Epoch: [ 0] [  465/  468] time: 119.5079, train_loss: 0.21226358, train_accuracy: 0.9375, test_Accuracy: 0.9590\n",
            "Epoch: [ 0] [  466/  468] time: 119.7587, train_loss: 0.16646284, train_accuracy: 0.9688, test_Accuracy: 0.9609\n",
            "Epoch: [ 0] [  467/  468] time: 119.9888, train_loss: 0.07353371, train_accuracy: 0.9844, test_Accuracy: 0.9614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Weight Initialization\n",
        "- 실제 로스 그래프는 굉장히 복잡해서 local minima로 학습을 하게 된다면, global minima보다 성능이 좋지 않을 것임\n",
        "- 따라서 weight 초기화는 네트워크가 어떤 출발지점에서 loss를 찾아가는 것인지 정하는 것이며, Xavier는 이런 것을 잘 정하는 것을 도와주는 방법중 하나임. \n",
        "- He initialization은 Relu함수에 사용하면 좋은 웨이트 초기화법임. 분산은 자비어에 보다 2배 더 큼"
      ],
      "metadata": {
        "id": "vKR9jw86aHHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class create_model_class_Xavier(tf.keras.Model):\n",
        "    def __init__(self, label_dim):\n",
        "        super(create_model_class_Xavier, self).__init__()\n",
        "        weight_init = tf.keras.initializers.glorot_uniform()\n",
        "\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(flatten())\n",
        "\n",
        "        for i in range(2):\n",
        "            self.model.add(dense(256, weight_init))\n",
        "            self.model.add(relu())\n",
        "\n",
        "        self.model.add(dense(label_dim, weight_init))\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "        x = self.model(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "p14TujJxaJiF"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Model \"\"\"\n",
        "network2 = create_model_class_Xavier(label_dim)\n",
        "\n",
        "\"\"\" Training \"\"\"\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "\"\"\" Writer \"\"\"\n",
        "checkpoint_dir = 'checkpoints'\n",
        "logs_dir = 'logs'\n",
        "\n",
        "model_dir = 'nn_softmax'\n",
        "\n",
        "checkpoint_dir = os.path.join(checkpoint_dir, model_dir)\n",
        "check_folder(checkpoint_dir)\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, model_dir)\n",
        "logs_dir = os.path.join(logs_dir, model_dir)"
      ],
      "metadata": {
        "id": "m1_bVywXu3Qj"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_flag :\n",
        "\n",
        "    checkpoint = tf.train.Checkpoint(dnn=network2)\n",
        "\n",
        "    # create writer for tensorboard\n",
        "    summary_writer = tf.summary.create_file_writer(logdir=logs_dir)\n",
        "    start_time = time()\n",
        "\n",
        "    # restore check-point if it exits\n",
        "    could_load, checkpoint_counter = load(network2, checkpoint_dir)    \n",
        "\n",
        "    if could_load:\n",
        "        start_epoch = (int)(checkpoint_counter / training_iterations)        \n",
        "        counter = checkpoint_counter        \n",
        "        print(\" [*] Load SUCCESS\")\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        start_iteration = 0\n",
        "        counter = 0\n",
        "        print(\" [!] Load failed...\")\n",
        "    \n",
        "    # train phase\n",
        "    with summary_writer.as_default():  # for tensorboard\n",
        "        for epoch in range(start_epoch, training_epochs):\n",
        "            for idx, (train_input, train_label) in enumerate(train_dataset):            \n",
        "                grads = grad(network2, train_input, train_label)\n",
        "                optimizer.apply_gradients(grads_and_vars=zip(grads, network2.variables))\n",
        "\n",
        "                train_loss = loss_fn(network2, train_input, train_label)\n",
        "                train_accuracy = accuracy_fn(network2, train_input, train_label)\n",
        "                \n",
        "                for test_input, test_label in test_dataset:                \n",
        "                    test_accuracy = accuracy_fn(network2, test_input, test_label)\n",
        "\n",
        "                tf.summary.scalar(name='train_loss', data=train_loss, step=counter)\n",
        "                tf.summary.scalar(name='train_accuracy', data=train_accuracy, step=counter)\n",
        "                tf.summary.scalar(name='test_accuracy', data=test_accuracy, step=counter)\n",
        "\n",
        "                print(\n",
        "                    \"Epoch: [%2d] [%5d/%5d] time: %4.4f, train_loss: %.8f, train_accuracy: %.4f, test_Accuracy: %.4f\" \\\n",
        "                    % (epoch, idx, training_iterations, time() - start_time, train_loss, train_accuracy,\n",
        "                       test_accuracy))\n",
        "                counter += 1                \n",
        "        checkpoint.save(file_prefix=checkpoint_prefix + '-{}'.format(counter))\n",
        "        \n",
        "# test phase      \n",
        "else :\n",
        "    _, _ = load(network, checkpoint_dir)\n",
        "    for test_input, test_label in test_dataset:    \n",
        "        test_accuracy = accuracy_fn(network2, test_input, test_label)\n",
        "\n",
        "    print(\"test_Accuracy: %.4f\" % (test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERImLV5xulFO",
        "outputId": "ff9d5da8-9232-4250-8b3d-d1e4d339ffbb"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [*] Reading checkpoints...\n",
            " [*] Success to read nn_softmax-468-1\n",
            " [*] Load SUCCESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "N-R_p0zxvPsx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}